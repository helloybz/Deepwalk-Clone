(this["webpackJsonpdeepwalk-demo"]=this["webpackJsonpdeepwalk-demo"]||[]).push([[0],{63:function(e,n,t){},70:function(e,n,t){"use strict";t.r(n);var a=t(0),r=t.n(a),l=t(48),o=t.n(l),i=(t(63),t(94)),s=t(97),d=t(103),h=t(104),c=t(89),u=t(2);function m(){return Object(u.jsx)(c.a,{children:Object(u.jsx)(s.a,{position:"fixed",sx:{backgroundImage:"none",bgcolor:"background.dark",borderBottomStyle:"solid",borderBottomWidth:"1px",borderBottomColor:"divider.dark"},children:Object(u.jsx)(d.a,{children:Object(u.jsx)(h.a,{sx:{fontSize:"h5.fontSize",fontWeight:"600",color:"text.dark",":hover":{cursor:"pointer"}},onClick:function(){return window.location.href="/"},children:"helloybz."})})})})}var p=t(18),g=t(100),f=t(106),b=t(101),k=t(99),x=t(69),j=t(52);function w(e){var n=e.data,t=e.title,a=Object(x.a)();return Object(u.jsx)(j.a,{width:"100%",height:"100%",chartType:"ScatterChart",data:n,options:{title:t,titleTextStyle:{color:"white"},legend:{position:"right",textStyle:{color:"white",fontSize:"2rem"}},backgroundColor:a.palette.background.dark,colors:["magenta","yellow","grey","cyan"],hAxis:{gridlines:{color:a.palette.divider.dark},minorGridlines:{color:a.palette.divider.dark},baseline:{color:a.palette.divider.dark},viewWindow:{max:1.5,min:-4}},vAxis:{gridlines:{color:a.palette.divider.dark},minorGridlines:{color:a.palette.divider.dark},baseline:{color:a.palette.divider.dark},viewWindow:{max:2.5,min:-2}}}})}var y=[{header:{eng:"Introduction",kor:"\ud504\ub85c\uc81d\ud2b8 \uc18c\uac1c"},content:{type:"list",eng:"                Implements Deepwalk algorithm based on the original paper without reference to the original source code.\n                Focused on implementing the same Deepwalk described in the paper.\n                Compared with the original Deepwalk by node classification experiment.\n                PyTorch is mainly used for this implementation.",kor:"                Deepwalk \ub17c\ubb38\uc744 \uad6c\ud604\ud55c \ud504\ub85c\uc81d\ud2b8\uc785\ub2c8\ub2e4.\n                \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc11c\uc220\ud55c \ub0b4\uc6a9\uc744 \uac00\ub2a5\ud55c \ucda9\uc2e4\ud788 \uad6c\ud604\ud588\uc2b5\ub2c8\ub2e4.\n                \uc5bc\ub9c8\ub098 \uc815\ud655\ud788 \uad6c\ud604\ud588\ub294\uc9c0 \uce21\uc815\ud558\uae30 \uc704\ud574\uc11c Deepwalk\uc640 \uc131\ub2a5\uc744 \ube44\uad50\ud558\ub294 \uc2e4\ud5d8\uc744 \ud588\uc2b5\ub2c8\ub2e4.\n                PyTorch\ub97c \uc774\uc6a9\ud574 \uad6c\ud604\ud588\uc2b5\ub2c8\ub2e4."}},{header:{eng:"Understanding Deepwalk",kor:"Deepwalk \uc774\ud574\ud558\uae30"},content:{type:"paragraphs",eng:"                Deepwalk is one of the most popular node embedding algorithms.                The algorithm consists of two parts: 1) populating random walks from a given network and 2) running Skipgram.                \n                Given a network, we can think of a random walk starting from a random node in the network.                The network's structural information around the starting node is incorporated in the random walk.                If a bunch of random walks are populated, starting from any random nodes,                 we can think that the network's entire structural information is almost captured in them.\n                Deepwalk considers the random walks as sentences and the nodes in them as words,                 and then applies Skipgram, a language modeling algorithm, to the random walks.                Skipgram's objective function is a likelihood of the nodes' vector representation given their adjacent nodes.\n                But the function is not feasible due to the expensive time complexity for                 computing the probability of collocation for the every node.                By adopting hierarchical softmax for that, the time complexity reduces to logarithms scale.                After maximizing this objective function, the vector representations of the nodes are optimized to be incorporating the network's structure.                ",kor:"                Deepwalk\ub294 \ub300\ud45c\uc801\uc778 node embedding \uc54c\uace0\ub9ac\uc998 \uc911 \ud558\ub098\uc785\ub2c8\ub2e4.                Deepwalk \uc54c\uace0\ub9ac\uc998\uc740 \ud06c\uac8c \ub450 \ubd80\ubd84\uc73c\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4.                \uccab\uc9f8\ub294 \uc8fc\uc5b4\uc9c4 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c Random Walk \uc0d8\ud50c\ub4e4\uc744 \ub9ce\uc774 \ud655\ubcf4\ud558\ub294 \uac83\uc774\uace0, \ub458\uc9f8\ub294 Skipgram\uc744 \uc801\uc6a9\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n                \uc5b4\ub5a4 \ub124\ud2b8\uc6cc\ud06c\uac00 \uc8fc\uc5b4\uc84c\uc744 \ub54c, \uadf8 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c \uc544\ubb34 Node\ub97c \ud558\ub098 \uace8\ub77c\uc11c \uadf8 Node\uc5d0\uc11c \uc2dc\uc791\ud558\ub294 Random Walk\ub97c \ud55c\ubc88 \uc2dc\ud589\ud588\ub2e4\uace0 \uc0dd\uac01\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.                \uadf8 \ud558\ub098\uc758 Random Walk \uc0d8\ud50c\uc5d0\ub294 \uadf8 Node \uc8fc\ubcc0\uc758 \uad6c\uc870\uc801\uc778 \uc815\ubcf4\uac00 \ub2f4\uaca8\uc788\uc2b5\ub2c8\ub2e4.                \ub9cc\uc57d \uc774\ub7f0 \uacfc\uc815\uc744 \ubaa8\ub4e0 Node\uc5d0 \ub300\ud574 \ubb34\uc218\ud788 \ub9ce\uc774 \uc2dc\ud589\ud55c\ub2e4\uba74, \uadf8\ub807\uac8c \uc5bb\uc740 Random Walk \uc0d8\ud50c\ub4e4\uc5d0\ub294 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc804\uccb4\uc801\uc778 \uad6c\uc870\uc801\uc778 \uc815\ubcf4\uac00 \ub2f4\uaca8\uc788\ub2e4\uace0 \uc0dd\uac01\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.                \n                \uc218\ub9ce\uc740 Random Walk \uc0d8\ud50c\ub4e4\uc744 \ubb38\uc7a5\uc73c\ub85c, \uadf8 \uc548\uc758 Node\ub4e4\uc744 \ub2e8\uc5b4\ub85c \uac04\uc8fc\ud558\uace0, \uc5b8\uc5b4 \ubaa8\ub378\ub9c1 \uc54c\uace0\ub9ac\uc998\uc778 Skipgram\uc744 \uc801\uc6a9\ud569\ub2c8\ub2e4.                \uc5b4\ub5a4 Node\uc758 \uc8fc\ubcc0 \uc815\ubcf4\uac00 \uc8fc\uc5b4\uc84c\uc744 \ub54c, \uadf8 Node\uc758 vector \ud45c\ud604\ud615\uc758 \uc6b0\ub3c4\ub97c \ubaa9\uc801\ud568\uc218\ub85c \uc0bc\uc2b5\ub2c8\ub2e4.                \uc774 \ubaa9\uc801\ud568\uc218\ub97c \ucd5c\ub300\ud55c \ud06c\uac8c \ud558\ub3c4\ub85d vector \ud45c\ud604\ud615\ub4e4\uc744 \ucd5c\uc801\ud654\ud558\uba74, \ub124\ud06c\uc6cc\ud2b8\uc758 \uad6c\uc870\uc801\uc778 \uc815\ubcf4\ub97c \uc798 \ubc18\uc601\ud55c Embedding\uc744 \uc5bb\ub294 \uac83\uc785\ub2c8\ub2e4.\n                \uadf8\ub7f0\ub370 \uc774 \ubaa9\uc801\ud568\uc218\ub97c \uacc4\uc0b0\ud558\ub294 \ub370 \uac78\ub9ac\ub294 \uc2dc\uac04\uc774 \ub124\ud2b8\uc6cc\ud06c \ub0b4 \uc874\uc7ac\ud558\ub294 node\ub4e4\uc758 \uc22b\uc790\uc5d0 \ube44\ub840\ud558\uae30 \ub54c\ubb38\uc5d0, \ud604\uc2e4\uc801\uc73c\ub85c \uacc4\uc0b0\uc774 \uc5b4\ub835\uc2b5\ub2c8\ub2e4.                \uc774 \ub17c\ubb38\uc5d0\uc11c\ub294 \ubaa9\uc801\ud568\uc218 \uacc4\uc0b0\uc5d0 Hierarchical Softmax\ub97c \ub3c4\uc785\ud574\uc11c, log(node\ub4e4\uc758 \uc22b\uc790)\uc5d0 \ube44\ub840\ud55c \uc2dc\uac04\uc548\uc5d0 \uacc4\uc0b0\uc744 \ud574\ub0c5\ub2c8\ub2e4.        "}},{header:{eng:"Implementing Deepwalk",kor:"Deepwalk \uad6c\ud604\ud558\uae30"},content:{type:"paragraphs",eng:"                First, I've implemented a graph structure, class Graph.                It inherits PyTorch's Dataset class, and emits one of its nodes by a given index.                Furthermore, the Graph has a method that returns the adjacent nodes of the given node.\n                Second, class RandomWalker, kind of wrapper class of the class Graph, is implemented.                It also inherits PyTorch's Dataset class, and generates a random walk on the graph starting from the given node.                The author of the original paper has populated random walk samples before running Skipgram.                But in this project, the random walks can be sampled not only during training time also in parallel by using PyTorch.\n                Second, a BinaryTree class is implemented for hierarchical softmax.                 While hierarchical softmax is an optmizing algorithm rather than a neural network architecture,                 BinaryTree class inherits PyTorch's nn.Module class because trainable binary classifiers are allocated to each node in the tree.                The vertices of the graph are allocated to the leaf nodes from left, and then the trainable parameters of the leaf nodes are used as the optimized vector representation of the nodes.                The class finds a path from the root node to the target leaf node, then the path are used to indexing the classifiers.\n                Third, a Skipgram class is implemented.                While the author has used 'gensim' library to apply Skipgram, I implement it myself using PyTorch for practicing pursose.                It captures the local structure of the graph by sliding window on the random walk samples,                then populates pairs of the nodes collocating in the window.                Also, it updates the BinaryTree's parameter for the probabilty of being the pairs to be maximized.            ",kor:"                First, I've implemented a graph structure, class Graph.                It inherits PyTorch's Dataset class, and emits one of its nodes by a given index.                Furthermore, the Graph has a method that returns the adjacent nodes of the given node.\n                Second, class RandomWalker, kind of wrapper class of the class Graph, is implemented.                It also inherits PyTorch's Dataset class, and generates a random walk on the graph starting from the given node.                The author of the original paper has populated random walk samples before running Skipgram.                But in this project, the random walks can be sampled not only during training time also in parallel by using PyTorch.\n                Second, a BinaryTree class is implemented for hierarchical softmax.                 While hierarchical softmax is an optmizing algorithm rather than a neural network architecture,                 BinaryTree class inherits PyTorch's nn.Module class because trainable binary classifiers are allocated to each node in the tree.                The vertices of the graph are allocated to the leaf nodes from left, and then the trainable parameters of the leaf nodes are used as the optimized vector representation of the nodes.                The class finds a path from the root node to the target leaf node, then the path are used to indexing the classifiers.\n                Third, a Skipgram class is implemented.                While the author has used 'gensim' library to apply Skipgram, I implement it myself using PyTorch for practicing pursose.                It captures the local structure of the graph by sliding window on the random walk samples,                then populates pairs of the nodes collocating in the window.                Also, it updates the BinaryTree's parameter for the probabilty of being the pairs to be maximized.            "}},{header:{eng:"Conclusion",kor:" \uacb0\ub860"},content:{type:"list",eng:"TBA",kor:"\ucd94\uac00\uc608\uc815"}}],v={zachary:[["x","Group A","Group B","Group C","Group D"],[-3.8166658878326416,-.5474966764450073,null,null,null],[-2.6906471252441406,.59298175573349,null,null,null],[-2.626798391342163,null,1.170506238937378,null,null],[-1.7017648220062256,.2615310847759247,null,null,null],[-1.5637834072113037,null,null,-1.3880661725997925,null],[-1.8370107412338257,null,null,-.9987485408782959,null],[-1.54941725730896,null,null,-.6557814478874207,null],[-1.2537076473236084,-.5925015211105347,null,null,null],[-1.5569331645965576,null,null,null,.08960134536027908],[-1.2568892240524292,null,.07699773460626602,null,null],[-1.0821958780288696,null,null,-1.3379249572753906,null],[-1.2867532968521118,-.9995964765548706,null,null,null],[-1.2120288610458374,-.8372260928153992,null,null,null],[-1.2340707778930664,-.05409325286746025,null,null,null],[-.07648933678865433,null,null,null,-.4845717251300812],[-.4363250434398651,null,null,null,-.34613025188446045],[-1.29430091381073,null,null,-.7885195016860962,null],[-1.2804150581359863,.7749748826026917,null,null,null],[.16352751851081848,null,null,null,.38466426730155945],[-1.3203083276748657,.2304065078496933,null,null,null],[-.9027239084243774,null,null,null,-.12415960431098938],[-1.3178577423095703,.4524197280406952,null,null,null],[-.8319980502128601,null,null,null,-.7561876773834229],[.02225770801305771,null,null,null,.6341503262519836],[-1.0112390518188477,null,2.24466872215271,null,null],[-.5600841641426086,null,1.824853539466858,null,null],[.7953892350196838,null,null,null,-1.6803532838821411],[-.7370090484619141,null,1.6600260734558105,null,null],[-1.03105628490448,null,1.5013389587402344,null,null],[.8226757645606995,null,null,null,-1.197110891342163],[-1.3952890634536743,null,null,null,-.24407616257667542],[-1.2003569602966309,null,1.6307902336120605,null,null],[-.9227609038352966,null,null,null,.10339689254760742],[-.6735153794288635,null,null,null,-.6007634997367859]]},O=t(105),T=t(96);function S(e){var n=e.type,t=e.content,a=e.language;if("list"===n){var r=null;return r="KOR"===a?t.kor.split("\n"):t.eng.split("\n"),Object(u.jsx)(g.a,{container:!0,component:O.a,children:r.map((function(e,n){return Object(u.jsxs)(g.a,{item:!0,xs:12,component:T.a,children:["- ",e]},n)}))})}if("paragraphs"===n){var l=null;return l="KOR"===a?t.kor.split("\n"):t.eng.split("\n"),Object(u.jsx)(g.a,{container:!0,component:O.a,children:l.map((function(e,n){return Object(u.jsx)(g.a,{item:!0,xs:12,component:T.a,children:Object(u.jsx)(h.a,{paragraph:!0,children:e})},n)}))})}}function B(){var e=Object(a.useState)("KOR"),n=Object(p.a)(e,2),t=n[0],r=n[1];return Object(u.jsxs)(g.a,{container:!0,component:i.a,sx:{padding:{xs:"0 1rem",md:"0 5rem",lg:"0 30rem"}},children:[Object(u.jsx)(f.a,{sx:{position:"fixed",bottom:{xs:"1rem",lg:"15rem"},right:{xs:"1rem",lg:"15rem"},zIndex:1e3},onClick:function(){r("KOR"===t?"ENG":"KOR")},children:t}),Object(u.jsxs)(g.a,{item:!0,component:h.a,xs:12,sx:{color:"text.dark",fontSize:{xs:"2.5rem",md:"3rem"},fontWeight:"600",lineHeight:{xs:"2.5rem",md:"3rem"},marginBottom:"1rem"},container:!0,children:[Object(u.jsx)(g.a,{item:!0,xs:12,md:"auto",children:"Deepwalk-Clone"}),Object(u.jsx)(g.a,{component:b.a,sx:{marginLeft:"2rem",fontSize:"2rem",borderStyle:"solid",borderWidth:"1px",borderColor:"divider.dark",borderRadius:"5rem",":hover":{cursor:"pointer"}},onClick:function(){return window.location.href="https://github.com/helloybz/deepwalk-clone"},children:Object(u.jsx)(k.a,{})})]}),Object(u.jsx)(g.a,{item:!0,xs:12,lg:12,sx:{marginBottom:"1rem",height:{xs:"20rem",lg:"40rem"}},children:Object(u.jsx)(w,{data:v.zachary,title:"Zachary Karate Club"})}),y.map((function(e,n){return Object(u.jsxs)(g.a,{item:!0,xs:12,sx:{marginBottom:"1rem"},children:[Object(u.jsx)(h.a,{variant:"h2",sx:{color:"rgb(243, 246, 249)",fontSize:"2rem",lineHeight:"2rem",marginBottom:"0.5rem",fontWeight:"1000"},children:"KOR"===t?e.header.kor:e.header.eng}),Object(u.jsx)(h.a,{sx:{color:"rgb(243, 246, 249)",fontSize:"1.2rem"},children:Object(u.jsx)(S,{type:e.content.type,content:e.content,language:t})})]},n)}))]})}var z=function(){return Object(u.jsxs)("div",{children:[Object(u.jsx)(m,{}),Object(u.jsx)(i.a,{sx:{marginTop:"6rem"},children:Object(u.jsx)(B,{})})]})},D=function(e){e&&e instanceof Function&&t.e(3).then(t.bind(null,107)).then((function(n){var t=n.getCLS,a=n.getFID,r=n.getFCP,l=n.getLCP,o=n.getTTFB;t(e),a(e),r(e),l(e),o(e)}))},I=t(102),W=t(44),C=Object(W.a)({palette:{mode:"dark",primary:{main:"#fff",dark:"#fff"},background:{default:"rgb(13, 25, 40)",dark:"rgb(13, 25, 40)"},text:{dark:"rgb(243, 246, 249)"},divider:{dark:"rgb(24, 47, 75)"}}});o.a.render(Object(u.jsx)(r.a.StrictMode,{children:Object(u.jsx)(I.a,{theme:C,children:Object(u.jsx)(z,{})})}),document.getElementById("root")),D()}},[[70,1,2]]]);
//# sourceMappingURL=main.298e5f57.chunk.js.map